package AI::OpenAI::TruncationObject 0.01;
# DO NOT EDIT! This is an autogenerated file.
use 5.020;
use Moo 2;
use experimental 'signatures';
use stable 'postderef';
use Types::Standard qw(Enum Str Bool Num Int HashRef ArrayRef);
use MooX::TypeTiny;

=head1 NAME

AI::OpenAI::TruncationObject -

=head1 SYNOPSIS

  my $obj = AI::OpenAI::TruncationObject->new();
  ...

=cut

sub as_hash( $self ) {
    return { $self->%* }
}

=head1 PROPERTIES

=head2 C<< last_messages >>

The number of most recent messages from the thread when constructing the context for the run.

=cut

has 'last_messages' => (
    is       => 'ro',
    isa      => Int,
);

=head2 C<< type >>

The truncation strategy to use for the thread. The default is `auto`. If set to `last_messages`, the thread will be truncated to the n most recent messages in the thread. When set to `auto`, messages in the middle of the thread will be dropped to fit the context length of the model, `max_prompt_tokens`.

=cut

has 'type' => (
    is       => 'ro',
    isa      => Enum[
        "auto",
        "last_messages",
    ],
    required => 1,
);


1;
